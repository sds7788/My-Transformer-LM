_wandb:
    value:
        cli_version: 0.21.0
        e:
            02t73gzz37idvancmoo3mnqa52hordw6:
                codePath: train/train_lm.py
                codePathLocal: train_lm.py
                cpu_count: 10
                cpu_count_logical: 20
                cudaVersion: "12.9"
                disk:
                    /:
                        total: "1081101176832"
                        used: "114923601920"
                email: suidesong@mail.ustc.edu.cn
                executable: /home/sds/miniconda3/envs/llm/bin/python
                git:
                    commit: 248c2866a65a19ecea3550727faf338f2afcd408
                    remote: https://github.com/sds7788/My-Transformer-LM.git
                gpu: NVIDIA GeForce RTX 4060 Laptop GPU
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      memoryTotal: "8585740288"
                      name: NVIDIA GeForce RTX 4060 Laptop GPU
                      uuid: GPU-c6402106-bced-ff1e-ec70-1877a556a8f4
                host: sds
                memory:
                    total: "8185561088"
                os: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
                program: /mnt/d/桌面/CS336-LLM/train/train_lm.py
                python: CPython 3.11.13
                root: /mnt/d/桌面/CS336-LLM/train
                startedAt: "2025-07-31T05:18:42.204576Z"
                writerId: 02t73gzz37idvancmoo3mnqa52hordw6
        m: []
        python_version: 3.11.13
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 16
            "4": 3.11.13
            "5": 0.21.0
            "12": 0.21.0
            "13": linux-x86_64
batch_size:
    value: 32
clip_grad_norm:
    value: 1
context_length:
    value: 256
cosine_iters:
    value: 10000
d_ff:
    value: 1344
d_model:
    value: 512
log_interval:
    value: 1
lr:
    value: 0.0002
min_lr:
    value: 1e-05
num_heads:
    value: 16
num_layers:
    value: 4
resume_checkpoint:
    value: 5000
rope_theta:
    value: 10000
save_interval:
    value: 1000
train_steps:
    value: 6000
val_batches:
    value: 10
val_interval:
    value: 100
vocab_size:
    value: 10000
warmup_iters:
    value: 500
weight_decay:
    value: 0.01
